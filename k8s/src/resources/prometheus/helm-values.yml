# Taken from: https://picluster.ricsanfre.com/docs/prometheus/

prometheusOperator:
  # Resources for the operator
  resources:
    requests:
      memory: 192Mi
      cpu: 75m
    limits:
      memory: 384Mi
      cpu: 300m
  # Relabeling job name for operator metrics
  serviceMonitor:
    relabelings:
      # Replace job value
      - sourceLabels:
          - __address__
        action: replace
        targetLabel: job
        replacement: prometheus-operator
  # Disable creation of kubelet service
  kubeletService:
    enabled: false
alertmanager:
  alertmanagerSpec:
    # Subpath /alertmanager configuration
    externalUrl: http://monitoring.${NETWORK_HOSTNAME_SUFFIX}/alertmanager/
    routePrefix: /
    # Resources configuration
    resources:
      requests:
        memory: 128Mi
        cpu: 50m
      limits:
        memory: 256Mi
        cpu: 250m
    # PVC configuration
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi
  # ServiceMonitor job relabel
  serviceMonitor:
    relabelings:
      # Replace job value
      - sourceLabels:
          - __address__
        action: replace
        targetLabel: job
        replacement: alertmanager
prometheus:
  prometheusSpec:
    containers:
      - name: prometheus
        startupProbe:
          failureThreshold: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          timeoutSeconds: 10
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 5
          timeoutSeconds: 10
          periodSeconds: 5
    # Subpath /prometheus configuration
    externalUrl: http://monitoring.${NETWORK_HOSTNAME_SUFFIX}/prometheus/
    routePrefix: /
    # Data retention configuration
    retention: 21d
    retentionSize: 12GB
    walCompression: true
    # Resources request and limits
    resources:
      requests:
        memory: 768Mi
        cpu: 300m
      limits:
        memory: 2Gi
        cpu: 1500m
    # PVC configuration
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 15Gi
    # Global scrape configuration
    scrapeInterval: 60s
    scrapeTimeout: 15s
    evaluationInterval: 60s
    additionalScrapeConfigs:
      - job_name: "uptime"
        scrape_interval: 300s
        scrape_timeout: 15s
        scheme: http
        metrics_path: "/metrics"
        static_configs:
          - targets: ["uptime.${NETWORK_HOSTNAME_SUFFIX}"]
        basic_auth:
          username: ${UPTIME_USERNAME}
          password: ${UPTIME_PASSWORD}
  # ServiceMonitor job relabel
  serviceMonitor:
    relabelings:
      # Replace job value
      - sourceLabels:
          - __address__
        action: replace
        targetLabel: job
        replacement: prometheus
grafana:
  # Configuring /grafana subpath
  grafana.ini:
    server:
      domain: monitoring.${NETWORK_HOSTNAME_SUFFIX}
      root_url: "%(protocol)s://%(domain)s/grafana/"
      serve_from_sub_path: true
    database:
      # Enable WAL to reduce writer lock contention on SQLite
      wal: true
      # Keep connections private per process to avoid shared cache issues
      cache_mode: private
      # Cap open connections so sidecars don't overwhelm the lightweight SQLite backend
      max_open_conn: 5
      max_idle_conn: 5
  # Admin user password
  adminPassword: ${GRAFANA_PASSWORD}
  # Set timezone to be browser
  defaultDashboardsTimezone: browser
  # No extra plugins; avoids unsupported Angular panels on Grafana 11+
  # Resources configuration
  resources:
    requests:
      memory: 192Mi
      cpu: 75m
    limits:
      memory: 384Mi
      cpu: 300m
  # Improved liveness and readiness probes for Raspberry Pi
  livenessProbe:
    httpGet:
      path: /api/health
      port: 3000
    initialDelaySeconds: 120
    timeoutSeconds: 30
    periodSeconds: 30
    failureThreshold: 5
  readinessProbe:
    httpGet:
      path: /api/health
      port: 3000
    initialDelaySeconds: 30
    timeoutSeconds: 10
    periodSeconds: 10
    failureThreshold: 10
  # Persistence configuration
  persistence:
    enabled: true
    type: pvc
    size: 5Gi
    accessModes:
      - ReadWriteOnce
    storageClassName: longhorn
  # ServiceMonitor label and job relabel
  serviceMonitor:
    labels:
      release: monitoring
    relabelings:
      # Replace job value
      - sourceLabels:
          - __address__
        action: replace
        targetLabel: job
        replacement: grafana
  sidecar:
    dashboards:
      enabled: true
      labelValue: "true"
# Disabling monitoring of K8s services.
# Monitoring of K3S components will be configured out of monitoring
kubelet:
  enabled: false
kubeApiServer:
  enabled: false
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false
kubeEtcd:
  enabled: false
# Disable K8S Prometheus Rules
# Rules for K3S components will be configured out of monitoring
defaultRules:
  create: true
  rules:
    etcd: false
    k8s: false
    kubeApiserverAvailability: false
    kubeApiserverBurnrate: false
    kubeApiserverHistogram: false
    kubeApiserverSlos: false
    kubeControllerManager: false
    kubelet: false
    kubeProxy: false
    kubernetesApps: false
    kubernetesResources: false
    kubernetesStorage: false
    kubernetesSystem: true
    kubeScheduler: false
# Node Exporter configuration
nodeExporter:
  enabled: true
  resources:
    requests:
      memory: 48Mi
      cpu: 30m
    limits:
      memory: 96Mi
      cpu: 100m

# Kube State Metrics configuration
kube-state-metrics:
  resources:
    requests:
      memory: 96Mi
      cpu: 75m
    limits:
      memory: 192Mi
      cpu: 250m

crds:
  upgradeJob:
    enabled: true
